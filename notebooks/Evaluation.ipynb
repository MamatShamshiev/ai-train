{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58c8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.config.config import get_cfg\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "from ensemble_boxes import soft_nms\n",
    "\n",
    "\n",
    "from defs import ROOT, TRAIN_DATA_PATH, TRAIN_IMAGES_PATH, TRAIN_MASKS_PATH, VAL_DATA_PATH, VAL_IMAGES_PATH, VAL_MASKS_PATH\n",
    "from dt2.register import register_my_dataset\n",
    "from dt2.visualize import visualize_dataset_dict, visualize_batch_item\n",
    "from inference.predictor import get_predictor\n",
    "from inference.submit import prepare_submit, get_predictions_for_submit, prepare_detection_submit, prepare_segmentation_submit\n",
    "from inference.grid_search import run_grid_search\n",
    "from inference.ensemble import convert_instances_to_wbf_format, convert_wbf_format_to_instances\n",
    "from train import Trainer\n",
    "from baseline.evaluation.evaluation import calculation_map_050, calculate_meanIOU, competition_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7207de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\"cascade-R50-2fc-FrozenBN-bs=6\", \"FPN-res101-bs=6-multiscale\", \"panopticFPN-resnet50-bs=6-multiscale\", \"FPN-cascade-res50-GN-bs=2-multiscale\"] \n",
    "exp_dirs = [ROOT / \"outputs\" / exp_name for exp_name in exp_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6639c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PANOPTIC_FPN.COMBINED.ENABLED is no longer used.  model.inference(do_postprocess=) should be used to toggle postprocessing.\n",
      "PANOPTIC_FPN.COMBINED.ENABLED is no longer used.  model.inference(do_postprocess=) should be used to toggle postprocessing.\n",
      "PANOPTIC_FPN.COMBINED.ENABLED is no longer used.  model.inference(do_postprocess=) should be used to toggle postprocessing.\n",
      "PANOPTIC_FPN.COMBINED.ENABLED is no longer used.  model.inference(do_postprocess=) should be used to toggle postprocessing.\n",
      "100%|██████████| 411/411 [11:43<00:00,  1.71s/it]\n",
      "segmentation submit preparation: 100%|██████████| 411/411 [00:00<00:00, 165485.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.63s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.633\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:25<00:00, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection: 0.6332918441102816\n",
      "Segmentation: 0.8856245811886206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70899"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_threshes = [0.0001] * len(exp_dirs)\n",
    "nms_threshes = [0.5] * len(exp_dirs)\n",
    "ensemble_method = \"wbf\"\n",
    "ensemble_method_kwargs = {\"iou_thr\": 0.6} #, \"weights\": [1, 1, 1]}\n",
    "\n",
    "prepare_submit(VAL_IMAGES_PATH, Path(\".\"), exp_dirs, score_threshes, nms_threshes, ensemble_method, **ensemble_method_kwargs)\n",
    "competition_metric(str(VAL_DATA_PATH / \"coco.json\"), \"detection_predictions.json\",\n",
    "                   str(VAL_DATA_PATH / \"segmentation_gt.json\"), \"segmentation_predictions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d714f9",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b55586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\"cascade-R50-2fc-FrozenBN-bs=6\", \"FPN-res101-bs=6-multiscale\"]\n",
    "exp_dirs = [ROOT / \"outputs\" / exp_name for exp_name in exp_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d738e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshes = [[0.0001] * len(exp_dirs)]\n",
    "nms_threshes = [[0.5] * len(exp_dirs)]\n",
    "ensemble_methods = [\"wbf\"]\n",
    "ensemble_methods_kwargs = [{\"iou_thr\": 0.6, \"weights\": [1, 1]}]\n",
    "metrics = run_grid_search(VAL_IMAGES_PATH, Path(\".\"), exp_dirs, score_threshes, nms_threshes, ensemble_methods, ensemble_methods_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba720119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
